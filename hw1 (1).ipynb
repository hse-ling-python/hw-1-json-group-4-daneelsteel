{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i'm too lazy to switch keyboards, so it's all in english, sorry\n",
    "#here we import the modules we'll need to read, count, search and clean tweets\n",
    "import json\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "\n",
    "def get_file():\n",
    "    '''puts tweets into a python list line by line'''\n",
    "    twitter = []\n",
    "    for line in open('hw_3_twitter.json'):\n",
    "        twitter.append(json.loads(line))\n",
    "    return twitter\n",
    "\n",
    "def get_ids(elem):\n",
    "    '''gets the user's id'''\n",
    "    if 'id' in elem: #if it's still there\n",
    "        right = elem['user']['id']\n",
    "    elif 'status' in elem['delete']: #if it's gone\n",
    "        right = elem['delete']['status']['user_id']\n",
    "    return right\n",
    "\n",
    "def clean_tags(hashtags):\n",
    "    '''gets tags - they lie deeper'''\n",
    "    true_tags = []\n",
    "    for tag in hashtags:\n",
    "        for each in tag:\n",
    "            if 'text' in each:\n",
    "                true_tags.append(each['text'])\n",
    "    return true_tags\n",
    "\n",
    "def clean_tweets(tweet):\n",
    "    '''here we clean our tweets and lowercase them'''\n",
    "    tweet_low = tweet.lower()\n",
    "    tweet_final = tweet_low.translate(str.maketrans('', '', string.punctuation))\n",
    "    return tweet_final\n",
    "\n",
    "def main():\n",
    "    '''does all work'''\n",
    "    c = Counter()\n",
    "    twitter = get_file()\n",
    "    deleted_comms = 0\n",
    "    languages = []\n",
    "    orig_ids = []\n",
    "    repeated_ids = []\n",
    "    repetitions_count = 0\n",
    "    followers = {}\n",
    "    hashtags = []\n",
    "    apps = []\n",
    "    noretweets = []\n",
    "    final_tweets = []\n",
    "    better_list_for_repeats = []\n",
    "    for i in twitter: #analysis starts there - with getting id's\n",
    "        if get_ids(i) in orig_ids or get_ids(i) in repeated_ids:\n",
    "            repeated_ids.append(get_ids(i))\n",
    "            repetitions_count += 2\n",
    "        else:\n",
    "            orig_ids.append(get_ids(i))\n",
    "        if 'delete' in i: #work with deleted\n",
    "            deleted_comms += 1\n",
    "        else: #work with still existing\n",
    "            if 'source' in i: #detect source\n",
    "                app_used = re.search('>.+<', i['source']).group()\n",
    "                apps.append(app_used.strip('<>'))\n",
    "            if 'lang' in i: #detect language\n",
    "                languages.append(i['lang'])\n",
    "            if 'user' in i: #detect amount of followers\n",
    "                followers[i['user']['name']] = i['user']['followers_count']\n",
    "            if 'entities' in i: #detect hachtags\n",
    "                if not i['entities']['hashtags'] == []:\n",
    "                    hashtags.append(i['entities']['hashtags'])\n",
    "            if 'retweeted_status' not in i: #detect retweets and get rid of them\n",
    "                if 'extended_tweet' in i:\n",
    "                    noretweets.append(i['extended_tweet']['full_text'])\n",
    "                else:\n",
    "                    noretweets.append(i['text'])\n",
    "    print('\\n there are', len(twitter), 'tweets \\n')\n",
    "    percent_deleted = deleted_comms/len(twitter)\n",
    "    print(percent_deleted*100, '% of them are deleted \\n')\n",
    "    print('the 15 most common languages are: ', Counter(languages).most_common(15), '\\n')\n",
    "    for i in repeated_ids:\n",
    "        if i not in better_list_for_repeats:\n",
    "            better_list_for_repeats.append(i)\n",
    "    print(len(better_list_for_repeats)), 'people have written more than one tweet \\n')\n",
    "    true_tags = clean_tags(hashtags)\n",
    "    print('the 20 most popular tags are:', Counter(true_tags).most_common(20), '\\n')\n",
    "    for notretweet in noretweets: #clean tweets and give them to Counter\n",
    "        clean_tweets(notretweet)\n",
    "        final_tweets.append(notretweet)\n",
    "    for each in final_tweets:\n",
    "        c += Counter(each.split())\n",
    "    print('top-10 lemmas: ', Counter(c).most_common(10), '\\n')\n",
    "    f_list = list(followers.items())\n",
    "    f_list.sort(key=lambda i: i[1])\n",
    "    print('these 10 users have the biggest number of followers:', f_list[-10:], '\\n')\n",
    "    true_tags = clean_tags(hashtags)\n",
    "    print('the 10 most common apps are: ', Counter(apps).most_common(10), '\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
